#!/usr/bin/env python3
"""
Script to create modeling.ipynb with proper structure
"""

import json

# Define all cells
cells = [
    # Cell 0: Title
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# ÎœÎ¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎšÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ·Ï‚ Î•Î½Î­ÏÎ³ÎµÎ¹Î±Ï‚\n",
            "\n",
            "## Î£Ï„ÏŒÏ‡Î¿Ï‚\n",
            "Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÎµÎ¬Î½ Î· Î·Î¼ÎµÏÎ®ÏƒÎ¹Î± ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±Ï‚ ÎµÎ¯Î½Î±Î¹ **Î¥ÏˆÎ·Î»Î®** Î® **Î§Î±Î¼Î·Î»Î®** ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î¿Î½ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ Ï„Î¿Ï… Î½Î¿Î¹ÎºÎ¿ÎºÏ…ÏÎ¹Î¿Ï.\n",
            "\n",
            "## Î ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ·\n",
            "- **Target**: Season-adjusted high consumption (>15% Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿)\n",
            "- **Features**: ÎœÏŒÎ½Î¿ past-known features (lags, rolling stats, calendar)\n",
            "- **ÎœÎ¿Î½Ï„Î­Î»Î±**: Logistic Regression â†’ Random Forest â†’ XGBoost/LightGBM\n",
            "- **Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·**: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
            "\n",
            "## Î‘Ï€Î¿Ï†Ï…Î³Î® Data Leakage\n",
            "âœ… Î§ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿ features Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î³Î½Ï‰ÏƒÏ„Î¬ **Ï€ÏÎ¹Î½** Ï„Î·Î½ Î·Î¼Î­ÏÎ± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚  \n",
            "âœ… Season means Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Î½Ï„Î±Î¹ **Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ train set**  \n",
            "âœ… Scalers fit **Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ train**"
        ]
    },
    
    # Cell 1: Section header
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": ["---\n", "## 1. Imports & Setup"]
    },
    
    # Cell 2: Imports
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "from pathlib import Path\n",
            "\n",
            "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
            "from sklearn.compose import ColumnTransformer\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.metrics import (\n",
            "    accuracy_score, precision_score, recall_score, f1_score,\n",
            "    roc_auc_score, classification_report, confusion_matrix,\n",
            "    RocCurveDisplay\n",
            ")\n",
            "\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "np.random.seed(42)\n",
            "pd.set_option('display.max_columns', None)\n",
            "pd.set_option('display.precision', 3)\n",
            "\n",
            "DATA_DIR = Path('..') / 'data'\n",
            "RESULTS_DIR = Path('..') / 'results'\n",
            "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
            "\n",
            "print('âœ… Imports completed successfully')\n",
            "print(f'ğŸ“ Data directory: {DATA_DIR.absolute()}')\n",
            "print(f'ğŸ“Š Results directory: {RESULTS_DIR.absolute()}')"
        ]
    },
    
    # Cell 3: Load data header
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "## 2. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
            "\n",
            "Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± **raw** (Î¼Î· ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î±) Î·Î¼ÎµÏÎ®ÏƒÎ¹Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ preprocessing."
        ]
    },
    
    # Cell 4: Load data
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· train/val/test sets\n",
            "train = pd.read_csv(DATA_DIR / 'train_raw.csv', parse_dates=True, index_col=0)\n",
            "val = pd.read_csv(DATA_DIR / 'val_raw.csv', parse_dates=True, index_col=0)\n",
            "test = pd.read_csv(DATA_DIR / 'test_raw.csv', parse_dates=True, index_col=0)\n",
            "\n",
            "print('ğŸ“Š Dataset Shapes:')\n",
            "print(f'  Train: {train.shape} ({train.index.min().date()} â†’ {train.index.max().date()})')\n",
            "print(f'  Val:   {val.shape} ({val.index.min().date()} â†’ {val.index.max().date()})')\n",
            "print(f'  Test:  {test.shape} ({test.index.min().date()} â†’ {test.index.max().date()})')\n",
            "\n",
            "print('\\nğŸ“‹ Available columns:', train.shape[1])\n",
            "print('\\nğŸ” First 3 rows of train:')\n",
            "train.head(3)"
        ]
    },
    
    # Cell 5: Target definition header
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "## 3. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Target: Season-Adjusted High Consumption\n",
            "\n",
            "### Î“Î¹Î±Ï„Î¯ Season-Adjusted;\n",
            "Î— ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±Ï‚ ÎµÎ¾Î±ÏÏ„Î¬Ï„Î±Î¹ **Ï€Î¿Î»Ï** Î±Ï€ÏŒ Ï„Î·Î½ ÎµÏ€Î¿Ï‡Î®:\n",
            "- **Î§ÎµÎ¹Î¼ÏÎ½Î±Ï‚**: ~33 kWh/day (Î¸Î­ÏÎ¼Î±Î½ÏƒÎ·)\n",
            "- **ÎšÎ±Î»Î¿ÎºÎ±Î¯ÏÎ¹**: ~17 kWh/day (Ï‡Ï‰ÏÎ¯Ï‚ Î¸Î­ÏÎ¼Î±Î½ÏƒÎ·)\n",
            "\n",
            "Î‘Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎ¿Ï…Î¼Îµ **Î­Î½Î±Î½** Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ Î³Î¹Î± ÏŒÎ»Î¿ Ï„Î¿ Ï‡ÏÏŒÎ½Î¿, ÏŒÎ»ÎµÏ‚ Î¿Î¹ Ï‡ÎµÎ¹Î¼Ï‰Î½Î¹Î¬Ï„Î¹ÎºÎµÏ‚ Î¼Î­ÏÎµÏ‚ Î¸Î± ÎµÎ¯Î½Î±Î¹ \"high\" ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Î¿Î¹ ÎºÎ±Î»Î¿ÎºÎ±Î¹ÏÎ¹Î½Î­Ï‚ \"low\", Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿.\n",
            "\n",
            "### Î›ÏÏƒÎ·\n",
            "Î£Ï…Î³ÎºÏÎ¯Î½Î¿Ï…Î¼Îµ ÎºÎ¬Î¸Îµ Î¼Î­ÏÎ± Î¼Îµ Ï„Î¿Î½ **ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ** Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ Ï„Î·Ï‚:\n",
            "- **High Consumption** = ÎšÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· > 1.15 Ã— ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒÏ‚ Î¼Î­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚ (15% Ï€Î¬Î½Ï‰)\n",
            "- **Normal/Low Consumption** = ÎšÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· â‰¤ 1.15 Ã— ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒÏ‚ Î¼Î­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚\n",
            "\n",
            "### Î‘Ï€Î¿Ï†Ï…Î³Î® Data Leakage\n",
            "âœ… Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÎ¿ÏÏ‚ Î¼Î­ÏƒÎ¿Ï…Ï‚ **Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ Ï„Î¿ train set**  \n",
            "âœ… Î•Ï†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ Î¯Î´Î¹Î¿Ï…Ï‚ Î¼Î­ÏƒÎ¿Ï…Ï‚ ÏƒÏ„Î¿ val ÎºÎ±Î¹ test"
        ]
    },
    
    # Cell 6: Calculate season means
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏÎ½ Î¼Î­ÏƒÏ‰Î½ ÏŒÏÏ‰Î½ Î‘Î ÎŸ TRAIN ÎœÎŸÎÎŸ\n",
            "season_means = train.groupby('Season')['Daily_total_power'].mean()\n",
            "\n",
            "print('ğŸ“Š Î•Ï€Î¿Ï‡Î¹Î±ÎºÎ¿Î¯ ÎœÎ­ÏƒÎ¿Î¹ ÎŒÏÎ¿Î¹ ÎšÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ·Ï‚ (Î±Ï€ÏŒ train set):')\n",
            "print(season_means.sort_values(ascending=False).round(2))\n",
            "print(f'\\nğŸ“ˆ Î”Î¹Î±Ï†Î¿ÏÎ¬ Winter vs Summer: {(season_means[\"Winter\"] - season_means[\"Summer\"]):.2f} kWh/day')\n",
            "print(f'   Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ: {(season_means[\"Winter\"] / season_means[\"Summer\"] - 1)*100:.1f}% Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿ Ï„Î¿ Ï‡ÎµÎ¹Î¼ÏÎ½Î±')"
        ]
    },
    
    # Cell 7: Create target
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ season-adjusted deviation Î³Î¹Î± ÎºÎ¬Î¸Îµ set\n",
            "THRESHOLD = 1.15  # 15% Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ Î¼Î­ÏƒÎ¿ = High\n",
            "\n",
            "# Train\n",
            "train['season_mean'] = train['Season'].map(season_means)\n",
            "train['deviation_ratio'] = train['Daily_total_power'] / train['season_mean']\n",
            "y_train = (train['deviation_ratio'] > THRESHOLD).astype(int)\n",
            "\n",
            "# Validation (Ï‡ÏÎ®ÏƒÎ· train season_means!)\n",
            "val['season_mean'] = val['Season'].map(season_means)\n",
            "val['deviation_ratio'] = val['Daily_total_power'] / val['season_mean']\n",
            "y_val = (val['deviation_ratio'] > THRESHOLD).astype(int)\n",
            "\n",
            "# Test (Ï‡ÏÎ®ÏƒÎ· train season_means!)\n",
            "test['season_mean'] = test['Season'].map(season_means)\n",
            "test['deviation_ratio'] = test['Daily_total_power'] / test['season_mean']\n",
            "y_test = (test['deviation_ratio'] > THRESHOLD).astype(int)\n",
            "\n",
            "print(f'ğŸ¯ Target Definition: High Consumption = deviation_ratio > {THRESHOLD}')\n",
            "print(f'   (i.e., >15% Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ Ï„Î¿Î½ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿)\\n')\n",
            "\n",
            "print('ğŸ“Š Target Distribution:')\n",
            "print(f'  Train: {y_train.value_counts().to_dict()} â†’ {y_train.value_counts(normalize=True).round(3).to_dict()}')\n",
            "print(f'  Val:   {y_val.value_counts().to_dict()} â†’ {y_val.value_counts(normalize=True).round(3).to_dict()}')\n",
            "print(f'  Test:  {y_test.value_counts().to_dict()} â†’ {y_test.value_counts(normalize=True).round(3).to_dict()}')\n",
            "\n",
            "print('\\nâœ… Target is balanced (not too imbalanced)')"
        ]
    },
]

# Continue with more cells...
print("Creating modeling.ipynb with first 8 cells...")
print("Run this script to generate the notebook, then I'll add more cells in the next iteration.")

# Create notebook structure
notebook = {
    "cells": cells,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

# Save to file
output_path = '/home/konstantinos-papadogiannis/energy-data-mining/notebooks/modeling.ipynb'
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f"âœ… Created {output_path}")
print(f"ğŸ“Š Total cells: {len(cells)}")
print("\nÎ¤ÏÎ­Î¾Îµ Î±Ï…Ï„ÏŒ Ï„Î¿ cell Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ Ï„Î± Ï€ÏÏÏ„Î± 8 cells.")
print("ÎœÎµÏ„Î¬ Î¸Î± Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÏ‰ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± (features, models, evaluation).")
