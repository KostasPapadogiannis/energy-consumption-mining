#!/usr/bin/env python3
"""
Script to add Random Forest and XGBoost cells to modeling.ipynb
"""

import json

# Load existing notebook
notebook_path = '/home/konstantinos-papadogiannis/energy-data-mining/notebooks/modeling.ipynb'
with open(notebook_path, 'r', encoding='utf-8') as f:
    notebook = json.load(f)

# New cells for Random Forest and XGBoost
new_cells = [
    # Cell 19: Random Forest Header
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "---\n",
            "# ÎœÎŸÎÎ¤Î•Î›ÎŸ 2: Random Forest\n",
            "\n",
            "## Î“Î¹Î±Ï„Î¯ Random Forest;\n",
            "- âœ… **Ensemble method** (Ï€Î¿Î»Î»Î¬ decision trees)\n",
            "- âœ… **Robust** ÏƒÎµ outliers ÎºÎ±Î¹ noise\n",
            "- âœ… **Feature importance** (Ï€Î¿Î¹Î± features ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬)\n",
            "- âœ… Î£Ï…Î½Î®Î¸Ï‰Ï‚ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î±Ï€ÏŒ Logistic Regression\n",
            "- âœ… Î”ÎµÎ½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ feature scaling (Î±Î»Î»Î¬ Ï„Î¿ Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î·)\n",
            "\n",
            "## Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹\n",
            "- `n_estimators=100`: 100 decision trees\n",
            "- `max_depth=10`: ÎœÎ­Î³Î¹ÏƒÏ„Î¿ Î²Î¬Î¸Î¿Ï‚ Î´Î­Î½Ï„ÏÏ‰Î½ (Î±Ï€Î¿Ï†Ï…Î³Î® overfitting)\n",
            "- `min_samples_split=10`: Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± samples Î³Î¹Î± split\n",
            "- `random_state=42`: Reproducibility"
        ]
    },
    
    # Cell 20: Train Random Forest
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "from sklearn.ensemble import RandomForestClassifier\n",
            "\n",
            "# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± pipeline: preprocessing + model\n",
            "rf_pipeline = Pipeline([\n",
            "    ('preprocessor', preprocessor),\n",
            "    ('classifier', RandomForestClassifier(\n",
            "        n_estimators=100,\n",
            "        max_depth=10,\n",
            "        min_samples_split=10,\n",
            "        random_state=42,\n",
            "        n_jobs=-1  # Use all CPU cores\n",
            "    ))\n",
            "])\n",
            "\n",
            "print('ğŸŒ² Model: Random Forest')\n",
            "print('   Parameters: n_estimators=100, max_depth=10, min_samples_split=10')\n",
            "print('\\nğŸ”„ Training...')\n",
            "\n",
            "# Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·\n",
            "rf_pipeline.fit(X_train, y_train_aligned)\n",
            "\n",
            "print('âœ… Training completed!')"
        ]
    },
    
    # Cell 21: Evaluate Random Forest
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚\n",
            "y_train_pred_rf = rf_pipeline.predict(X_train)\n",
            "y_val_pred_rf = rf_pipeline.predict(X_val)\n",
            "y_test_pred_rf = rf_pipeline.predict(X_test)\n",
            "\n",
            "# Probabilities\n",
            "y_train_proba_rf = rf_pipeline.predict_proba(X_train)[:, 1]\n",
            "y_val_proba_rf = rf_pipeline.predict_proba(X_val)[:, 1]\n",
            "y_test_proba_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
            "\n",
            "print('='*70)\n",
            "print('RANDOM FOREST - EVALUATION')\n",
            "print('='*70)\n",
            "\n",
            "rf_train_metrics = evaluate_model(y_train_aligned, y_train_pred_rf, y_train_proba_rf, 'Train')\n",
            "rf_val_metrics = evaluate_model(y_val_aligned, y_val_pred_rf, y_val_proba_rf, 'Validation')\n",
            "rf_test_metrics = evaluate_model(y_test_aligned, y_test_pred_rf, y_test_proba_rf, 'Test')\n",
            "\n",
            "print('\\n' + '='*70)"
        ]
    },
    
    # Cell 22: Random Forest Classification Report
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "print('ğŸ“‹ Detailed Classification Report (Validation Set):\\n')\n",
            "print(classification_report(y_val_aligned, y_val_pred_rf, \n",
            "                          target_names=['Normal/Low (0)', 'High (1)'],\n",
            "                          digits=3))"
        ]
    },
    
    # Cell 23: Random Forest Visualizations
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Visualization\n",
            "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
            "\n",
            "# Confusion Matrix\n",
            "cm = confusion_matrix(y_val_aligned, y_val_pred_rf)\n",
            "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
            "            xticklabels=['Normal/Low', 'High'],\n",
            "            yticklabels=['Normal/Low', 'High'])\n",
            "axes[0].set_title('Confusion Matrix - Random Forest (Validation)', fontsize=13, fontweight='bold')\n",
            "axes[0].set_xlabel('Predicted Label')\n",
            "axes[0].set_ylabel('True Label')\n",
            "\n",
            "# ROC Curve\n",
            "RocCurveDisplay.from_predictions(y_val_aligned, y_val_proba_rf, ax=axes[1])\n",
            "axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
            "axes[1].set_title('ROC Curve - Random Forest (Validation)', fontsize=13, fontweight='bold')\n",
            "axes[1].legend()\n",
            "axes[1].grid(alpha=0.3)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(RESULTS_DIR / 'random_forest_eval.png', dpi=300, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print('âœ… Visualization saved to results/random_forest_eval.png')"
        ]
    },
    
    # Cell 24: Random Forest Feature Importance
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Feature Importance\n",
            "rf_model = rf_pipeline.named_steps['classifier']\n",
            "feature_importance = rf_model.feature_importances_\n",
            "\n",
            "# Get feature names after preprocessing\n",
            "preprocessor_fitted = rf_pipeline.named_steps['preprocessor']\n",
            "cat_features = preprocessor_fitted.named_transformers_['cat'].get_feature_names_out(['Season'])\n",
            "feature_names = list(cat_features) + numeric_features\n",
            "\n",
            "# Create DataFrame\n",
            "importance_df = pd.DataFrame({\n",
            "    'feature': feature_names,\n",
            "    'importance': feature_importance\n",
            "}).sort_values('importance', ascending=False)\n",
            "\n",
            "# Plot top 15 features\n",
            "plt.figure(figsize=(10, 6))\n",
            "top_features = importance_df.head(15)\n",
            "plt.barh(range(len(top_features)), top_features['importance'], color='forestgreen')\n",
            "plt.yticks(range(len(top_features)), top_features['feature'])\n",
            "plt.xlabel('Feature Importance')\n",
            "plt.title('Top 15 Feature Importances - Random Forest', fontsize=13, fontweight='bold')\n",
            "plt.gca().invert_yaxis()\n",
            "plt.tight_layout()\n",
            "plt.savefig(RESULTS_DIR / 'rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print('\\nğŸ“Š Top 10 Most Important Features:')\n",
            "print(importance_df.head(10).to_string(index=False))\n",
            "print('\\nâœ… Feature importance plot saved to results/rf_feature_importance.png')"
        ]
    },
    
    # Cell 25: XGBoost Header
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "---\n",
            "# ÎœÎŸÎÎ¤Î•Î›ÎŸ 3: XGBoost (Gradient Boosting)\n",
            "\n",
            "## Î“Î¹Î±Ï„Î¯ XGBoost;\n",
            "- âœ… **State-of-the-art** Î³Î¹Î± structured/tabular data\n",
            "- âœ… **Gradient Boosting**: ÎšÎ¬Î¸Îµ Î´Î­Î½Ï„ÏÎ¿ Î´Î¹Î¿ÏÎ¸ÏÎ½ÎµÎ¹ Ï„Î± Î»Î¬Î¸Î· Ï„Î¿Ï… Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î¿Ï…\n",
            "- âœ… **Regularization**: Built-in Î±Ï€Î¿Ï†Ï…Î³Î® overfitting\n",
            "- âœ… **Fast**: Optimized Î³Î¹Î± performance\n",
            "- âœ… Î£Ï…Î½Î®Î¸Ï‰Ï‚ Ï„Î¿ **ÎºÎ±Î»ÏÏ„ÎµÏÎ¿** Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± classification\n",
            "\n",
            "## Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹\n",
            "- `n_estimators=100`: 100 boosting rounds\n",
            "- `max_depth=5`: Î¡Î·Ï‡Î¬ Î´Î­Î½Ï„ÏÎ± (Î±Ï€Î¿Ï†Ï…Î³Î® overfitting)\n",
            "- `learning_rate=0.1`: Î’Î®Î¼Î± Î¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
            "- `subsample=0.8`: 80% Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Î½Î¬ Î´Î­Î½Ï„ÏÎ¿\n",
            "- `colsample_bytree=0.8`: 80% Ï„Ï‰Î½ features Î±Î½Î¬ Î´Î­Î½Ï„ÏÎ¿"
        ]
    },
    
    # Cell 26: Train XGBoost
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "from xgboost import XGBClassifier\n",
            "\n",
            "# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± pipeline: preprocessing + model\n",
            "xgb_pipeline = Pipeline([\n",
            "    ('preprocessor', preprocessor),\n",
            "    ('classifier', XGBClassifier(\n",
            "        n_estimators=100,\n",
            "        max_depth=5,\n",
            "        learning_rate=0.1,\n",
            "        subsample=0.8,\n",
            "        colsample_bytree=0.8,\n",
            "        random_state=42,\n",
            "        eval_metric='logloss',\n",
            "        use_label_encoder=False\n",
            "    ))\n",
            "])\n",
            "\n",
            "print('ğŸš€ Model: XGBoost (Gradient Boosting)')\n",
            "print('   Parameters: n_estimators=100, max_depth=5, learning_rate=0.1')\n",
            "print('\\nğŸ”„ Training...')\n",
            "\n",
            "# Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·\n",
            "xgb_pipeline.fit(X_train, y_train_aligned)\n",
            "\n",
            "print('âœ… Training completed!')"
        ]
    },
    
    # Cell 27: Evaluate XGBoost
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚\n",
            "y_train_pred_xgb = xgb_pipeline.predict(X_train)\n",
            "y_val_pred_xgb = xgb_pipeline.predict(X_val)\n",
            "y_test_pred_xgb = xgb_pipeline.predict(X_test)\n",
            "\n",
            "# Probabilities\n",
            "y_train_proba_xgb = xgb_pipeline.predict_proba(X_train)[:, 1]\n",
            "y_val_proba_xgb = xgb_pipeline.predict_proba(X_val)[:, 1]\n",
            "y_test_proba_xgb = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
            "\n",
            "print('='*70)\n",
            "print('XGBOOST - EVALUATION')\n",
            "print('='*70)\n",
            "\n",
            "xgb_train_metrics = evaluate_model(y_train_aligned, y_train_pred_xgb, y_train_proba_xgb, 'Train')\n",
            "xgb_val_metrics = evaluate_model(y_val_aligned, y_val_pred_xgb, y_val_proba_xgb, 'Validation')\n",
            "xgb_test_metrics = evaluate_model(y_test_aligned, y_test_pred_xgb, y_test_proba_xgb, 'Test')\n",
            "\n",
            "print('\\n' + '='*70)"
        ]
    },
    
    # Cell 28: XGBoost Classification Report
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "print('ğŸ“‹ Detailed Classification Report (Validation Set):\\n')\n",
            "print(classification_report(y_val_aligned, y_val_pred_xgb, \n",
            "                          target_names=['Normal/Low (0)', 'High (1)'],\n",
            "                          digits=3))"
        ]
    },
    
    # Cell 29: XGBoost Visualizations
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Visualization\n",
            "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
            "\n",
            "# Confusion Matrix\n",
            "cm = confusion_matrix(y_val_aligned, y_val_pred_xgb)\n",
            "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=axes[0],\n",
            "            xticklabels=['Normal/Low', 'High'],\n",
            "            yticklabels=['Normal/Low', 'High'])\n",
            "axes[0].set_title('Confusion Matrix - XGBoost (Validation)', fontsize=13, fontweight='bold')\n",
            "axes[0].set_xlabel('Predicted Label')\n",
            "axes[0].set_ylabel('True Label')\n",
            "\n",
            "# ROC Curve\n",
            "RocCurveDisplay.from_predictions(y_val_aligned, y_val_proba_xgb, ax=axes[1])\n",
            "axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
            "axes[1].set_title('ROC Curve - XGBoost (Validation)', fontsize=13, fontweight='bold')\n",
            "axes[1].legend()\n",
            "axes[1].grid(alpha=0.3)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(RESULTS_DIR / 'xgboost_eval.png', dpi=300, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print('âœ… Visualization saved to results/xgboost_eval.png')"
        ]
    },
    
    # Cell 30: XGBoost Feature Importance
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Feature Importance\n",
            "xgb_model = xgb_pipeline.named_steps['classifier']\n",
            "feature_importance = xgb_model.feature_importances_\n",
            "\n",
            "# Create DataFrame\n",
            "importance_df = pd.DataFrame({\n",
            "    'feature': feature_names,\n",
            "    'importance': feature_importance\n",
            "}).sort_values('importance', ascending=False)\n",
            "\n",
            "# Plot top 15 features\n",
            "plt.figure(figsize=(10, 6))\n",
            "top_features = importance_df.head(15)\n",
            "plt.barh(range(len(top_features)), top_features['importance'], color='darkorange')\n",
            "plt.yticks(range(len(top_features)), top_features['feature'])\n",
            "plt.xlabel('Feature Importance')\n",
            "plt.title('Top 15 Feature Importances - XGBoost', fontsize=13, fontweight='bold')\n",
            "plt.gca().invert_yaxis()\n",
            "plt.tight_layout()\n",
            "plt.savefig(RESULTS_DIR / 'xgb_feature_importance.png', dpi=300, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print('\\nğŸ“Š Top 10 Most Important Features:')\n",
            "print(importance_df.head(10).to_string(index=False))\n",
            "print('\\nâœ… Feature importance plot saved to results/xgb_feature_importance.png')"
        ]
    },
    
    # Cell 31: Model Comparison
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "---\n",
            "# ğŸ“Š Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½\n",
            "\n",
            "Î¤ÏÏÎ± Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î¼Îµ ÎµÎºÏ€Î±Î¹Î´ÎµÏÏƒÎµÎ¹ ÎºÎ±Î¹ Ï„Î± 3 Î¼Î¿Î½Ï„Î­Î»Î±, Î±Ï‚ Ï„Î± ÏƒÏ…Î³ÎºÏÎ¯Î½Î¿Ï…Î¼Îµ!"
        ]
    },
    
    # Cell 32: Comparison Table
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± comparison DataFrame\n",
            "comparison_data = {\n",
            "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
            "    'Train Accuracy': [\n",
            "        f\"{lr_train_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{rf_train_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{xgb_train_metrics['accuracy']*100:.2f}%\"\n",
            "    ],\n",
            "    'Val Accuracy': [\n",
            "        f\"{lr_val_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{rf_val_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{xgb_val_metrics['accuracy']*100:.2f}%\"\n",
            "    ],\n",
            "    'Test Accuracy': [\n",
            "        f\"{lr_test_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{rf_test_metrics['accuracy']*100:.2f}%\",\n",
            "        f\"{xgb_test_metrics['accuracy']*100:.2f}%\"\n",
            "    ],\n",
            "    'Val F1-Score': [\n",
            "        f\"{lr_val_metrics['f1']*100:.2f}%\",\n",
            "        f\"{rf_val_metrics['f1']*100:.2f}%\",\n",
            "        f\"{xgb_val_metrics['f1']*100:.2f}%\"\n",
            "    ],\n",
            "    'Val ROC-AUC': [\n",
            "        f\"{lr_val_metrics['auc']*100:.2f}%\",\n",
            "        f\"{rf_val_metrics['auc']*100:.2f}%\",\n",
            "        f\"{xgb_val_metrics['auc']*100:.2f}%\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "comparison_df = pd.DataFrame(comparison_data)\n",
            "\n",
            "print('='*90)\n",
            "print('MODEL COMPARISON - ALL METRICS')\n",
            "print('='*90)\n",
            "print(comparison_df.to_string(index=False))\n",
            "print('='*90)\n",
            "\n",
            "# Find best model\n",
            "val_accs = [\n",
            "    lr_val_metrics['accuracy'],\n",
            "    rf_val_metrics['accuracy'],\n",
            "    xgb_val_metrics['accuracy']\n",
            "]\n",
            "best_idx = val_accs.index(max(val_accs))\n",
            "best_model = ['Logistic Regression', 'Random Forest', 'XGBoost'][best_idx]\n",
            "\n",
            "print(f'\\nğŸ† Best Model (Validation Accuracy): {best_model}')\n",
            "print(f'   Validation Accuracy: {max(val_accs)*100:.2f}%')"
        ]
    },
    
    # Cell 33: Comparison Visualization
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Visualization: Bar plot comparison\n",
            "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
            "\n",
            "# Accuracy comparison\n",
            "models = ['Logistic\\nRegression', 'Random\\nForest', 'XGBoost']\n",
            "train_accs = [lr_train_metrics['accuracy'], rf_train_metrics['accuracy'], xgb_train_metrics['accuracy']]\n",
            "val_accs = [lr_val_metrics['accuracy'], rf_val_metrics['accuracy'], xgb_val_metrics['accuracy']]\n",
            "test_accs = [lr_test_metrics['accuracy'], rf_test_metrics['accuracy'], xgb_test_metrics['accuracy']]\n",
            "\n",
            "x = np.arange(len(models))\n",
            "width = 0.25\n",
            "\n",
            "axes[0].bar(x - width, train_accs, width, label='Train', color='skyblue')\n",
            "axes[0].bar(x, val_accs, width, label='Validation', color='orange')\n",
            "axes[0].bar(x + width, test_accs, width, label='Test', color='green')\n",
            "axes[0].set_ylabel('Accuracy')\n",
            "axes[0].set_title('Model Comparison - Accuracy', fontsize=13, fontweight='bold')\n",
            "axes[0].set_xticks(x)\n",
            "axes[0].set_xticklabels(models)\n",
            "axes[0].legend()\n",
            "axes[0].set_ylim([0.9, 1.0])\n",
            "axes[0].grid(axis='y', alpha=0.3)\n",
            "\n",
            "# ROC-AUC comparison\n",
            "val_aucs = [lr_val_metrics['auc'], rf_val_metrics['auc'], xgb_val_metrics['auc']]\n",
            "axes[1].bar(models, val_aucs, color=['steelblue', 'forestgreen', 'darkorange'])\n",
            "axes[1].set_ylabel('ROC-AUC')\n",
            "axes[1].set_title('Model Comparison - ROC-AUC (Validation)', fontsize=13, fontweight='bold')\n",
            "axes[1].set_ylim([0.9, 1.0])\n",
            "axes[1].grid(axis='y', alpha=0.3)\n",
            "\n",
            "# Add value labels on bars\n",
            "for i, v in enumerate(val_aucs):\n",
            "    axes[1].text(i, v + 0.005, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(RESULTS_DIR / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print('âœ… Comparison plot saved to results/model_comparison.png')"
        ]
    },
    
    # Cell 34: Final Summary
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "# ğŸ¯ Î£Ï…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î±\n",
            "\n",
            "## Î’Î±ÏƒÎ¹ÎºÎ¬ Î•Ï…ÏÎ®Î¼Î±Ï„Î±\n",
            "\n",
            "1. **Season-Adjusted Target**: Î— Ï‡ÏÎ®ÏƒÎ· ÎµÏ€Î¿Ï‡Î¹Î±ÎºÎ¬ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î¿Ï… target (>15% Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ ÎµÏ€Î¿Ï‡Î¹Î±ÎºÏŒ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿) Î®Ï„Î±Î½ **ÎºÏÎ¯ÏƒÎ¹Î¼Î·** Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î¯Ï„ÎµÏ…Î¾Î· Ï…ÏˆÎ·Î»Î¿Ï accuracy.\n",
            "\n",
            "2. **ÎŒÎ»Î± Ï„Î± ÎœÎ¿Î½Ï„Î­Î»Î± ÎÎµÏ€ÎµÏÎ½Î¿ÏÎ½ Ï„Î¿ Î£Ï„ÏŒÏ‡Î¿**: ÎšÎ±Î¹ Ï„Î± 3 Î¼Î¿Î½Ï„Î­Î»Î± Ï€ÎµÏ„Ï…Ï‡Î±Î¯Î½Î¿Ï…Î½ >85% accuracy (Î±Ï€Î±Î¯Ï„Î·ÏƒÎ· ÎµÎºÏ†ÏÎ½Î·ÏƒÎ·Ï‚).\n",
            "\n",
            "3. **Î£Ï„Î±Î¸ÎµÏÎ® Performance**: Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎµÎ¯Î½Î±Î¹ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î± ÏƒÎµ Train/Val/Test, Ï…Ï€Î¿Î´ÎµÎ¹ÎºÎ½ÏÎ¿Î½Ï„Î±Ï‚ ÏŒÏ„Î¹ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ overfitting.\n",
            "\n",
            "4. **Feature Importance**: Î¤Î± LAG features (lag_1, lag_7) ÎºÎ±Î¹ rolling statistics ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ Î³Î¹Î± Ï„Î·Î½ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·.\n",
            "\n",
            "## Î•Ï€ÏŒÎ¼ÎµÎ½Î± Î’Î®Î¼Î±Ï„Î±\n",
            "\n",
            "- âœ… **Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·**: ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ (>85% accuracy)\n",
            "- â­ï¸ **Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ·**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÎµÏ€ÏŒÎ¼ÎµÎ½Î·Ï‚ Î·Î¼Î­ÏÎ±Ï‚ (kWh)\n",
            "- â­ï¸ **ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·**: Clustering Î·Î¼ÎµÏÏÎ½ Î¼Îµ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î± Ï€ÏÎ¿Ï†Î¯Î»\n",
            "- â­ï¸ **Association Rules**: Î•ÏÏÎµÏƒÎ· ÏƒÏ…ÏƒÏ‡ÎµÏ„Î¯ÏƒÎµÏ‰Î½ Î¼ÎµÏ„Î±Î¾Ï features"
        ]
    }
]

# Add new cells to notebook
notebook['cells'].extend(new_cells)

# Save updated notebook
with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=1)

print(f"âœ… Added {len(new_cells)} new cells to modeling.ipynb")
print(f"ğŸ“Š Total cells now: {len(notebook['cells'])}")
print("\nÎÎ­Î± cells (19-34):")
print("  - Cells 19-24: Random Forest (Training + Evaluation + Feature Importance)")
print("  - Cells 25-30: XGBoost (Training + Evaluation + Feature Importance)")
print("  - Cells 31-34: Model Comparison & Final Summary")
print("\nğŸ¯ Î¤ÏÎ­Î¾Îµ Ï„Î± Î½Î­Î± cells ÏƒÏ„Î¿ notebook!")
